{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektarbeit Data Analytics\n",
    "\n",
    "Sebastian Jana,\n",
    "Sophie Jana\n",
    "\n",
    "## Inhaltsverzeichnis\n",
    "<a id =\"inhaltsverzeichnis\"></a>\n",
    "\n",
    "[1. Aufgabe](#aufgabe1)\n",
    "\n",
    "2. Aufgabe\n",
    "\n",
    "3. Aufgabe\n",
    "\n",
    "4. Aufgabe\n",
    "5. Aufgabe\n",
    "\n",
    "[6. Aufgabe](#aufgabe6)\n",
    "\n",
    "[7. Quellenverzeichnis](#quellenverzeichnis)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1 (Datenvorbereitung)\n",
    "<a id = \"aufgabe1\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a) Einlesen der CSV Dateien, welche die Stromerzeugungsdaten und die Börsenstrompreise enthalten, als Dataframe df_hourly.\n",
    "\n",
    "Nach dem ersten Zusammenführen haben wir festgestellt, dass die Datumsspalte je nach CSV-Datei unterschiedliche Namen für Sommerzeit und Winterzeit hat. Dies führt dazu, dass beim Zusammenführen zwei separate Spalten entstehen. Um dies zu vermeiden, prüfen wir bereits beim Einlesen der Dateien die Spaltennamen und führen sie zu einer einheitlichen Spalte „Datum“ im df_hourly zusammen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources for reading csv files from one folder[1],[2]\n",
    "path = './Daten/Strompreisdaten'\n",
    "# List all files (.csv) in the given path\n",
    "csv_files = glob.glob(os.path.join(path, \"*csv\"))\n",
    "\n",
    "df_list = []\n",
    "for i in range(len(csv_files)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(csv_files[i], sep = \",\")\n",
    "        for column in df_temp.columns:\n",
    "            # Combine the date columns, by getting rid of the naming difference in csv source\n",
    "            if 'Datum (MESZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MESZ)':'Datum'})\n",
    "            elif 'Datum (MEZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MEZ)':'Datum'})\n",
    "        df_list.append(df_temp)\n",
    "    except Exception as err: \n",
    "        print(\"Fehler beim Einlesen des Files: \", err)\n",
    "    \n",
    "df_hourly = pd.concat(df_list)\n",
    "df_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Zur besseren anschließenden Analyse überführen wir die Datumsspalte (vorher dytpe object) in ein Date-Time-Format. Überprüfung, ob nach der Konvertierung invalide Datumswerte existieren, was nicht der Fall ist.\n",
    "Alle anderen Spalten haben den dtype float64 und werden so belassen.\n",
    "Entfernung aller Datensätze, die nicht im Betrachtungszeitraum liegen (2020-2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_hourly.shape)\n",
    "# Converting the column \"Datum\" from dtype object to DateTime format\n",
    "# Invalid values are converted to NaT (Not a Time)\n",
    "# Source: [3]\n",
    "df_hourly['Datum'] = pd.to_datetime(df_hourly['Datum'], errors=\"coerce\")\n",
    "print(df_hourly.dtypes)\n",
    "\n",
    "\n",
    "print(df_hourly['Datum'].isna().any())\n",
    "\n",
    "# Erstelle eine Spalte mit dem Jahr aus der Datumsspalte\n",
    "df_hourly['Jahr'] = df_hourly['Datum'].dt.year\n",
    "\n",
    "# Filter: Jahre außerhalb des Bereichs 2020–2024\n",
    "df_false_year = df_hourly[(df_hourly['Jahr'] < 2020) | (df_hourly['Jahr'] > 2024)]\n",
    "\n",
    "print(df_false_year.shape)\n",
    "df_false_year\n",
    "#df_hourly = df_hourly[(df_hourly['Datum'] >= '2020-01-01') & (df_hourly['Datum'] <= '2024-12-31')]\n",
    "#df_hourly.shape\n",
    "#df_hourly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Beurteilung der Datenqualität und notwenige Datenbereinigungsschritte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 6 (Analyse von Stromtarif-Angeboten für Endkunden)\n",
    "<a id = \"aufgabe6\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a) Führen Sie die gegebenen Preisvergleichdaten in einem DataFrame namens df_cust zusammen. Exportieren Sie diesen als CSV-Datei namens prices_customers.csv und laden Sie diese mit Ihrer Abgabe auf Moodle hoch. Verwerfen Sie bitte zur Minimierung der Dateigröße alle Spalten, die im weiteren Verlauf nicht mehr verwendet werden. Kommentieren Sie nun den Code zur Datensatzgenerierung aus und lesen Sie die CSV-Datei in den DataFrame df_cust erneut aus dieser Datei ein.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path = './Daten/Endkundenpreise/'\n",
    "\n",
    "def extract_date_from_filepath(file):\n",
    "    file = file.replace(path, \"\")\n",
    "    # Concatenate the date out of fixed year 2024 and month/day from folder name\n",
    "    return \"2024-\" + file[0:5]\n",
    "\n",
    "def extract_data_from_json(file):\n",
    "    assert file.endswith(\".json\"), \"Keine json-Datei uebergeben\"\n",
    "    try:\n",
    "        # Read and load the json file\n",
    "        df_temp = pd.read_json(json_files[i])\n",
    "        # Transpose the table: convert the rows to columns\n",
    "        df_temp = df_temp.T\n",
    "        # Add date from filename as column\n",
    "        df_temp['Datum'] = extract_date_from_filepath(file)\n",
    "        \n",
    "        return df_temp\n",
    "    except:\n",
    "        print(\"Datei konnte nicht gelesen werden.\")\n",
    "\n",
    "def drop_unnecessary_columns(df):\n",
    "    columns_to_drop = ['Postleitzahl', 'Jahresverbrauch', 'Abschlagszahlung', 'Verlängerung', 'Kündigungsfrist', 'Grundpreis', 'Arbeitspreis', 'Preisgarantie', 'Grundpreisrabatt:', 'Neukundenbonus', 'Sofortbonus', 'Arbeitspreisrabatt', 'Zusätzlicher Aktionsbonus', 'Blitzbonus', 'Abschlagsrabatt', 'Grundpreisrabatt', 'Winterprämie']\n",
    "    return df.drop(columns = columns_to_drop)\n",
    "\n",
    "df_list = []\n",
    "# https://www.tutorialspoint.com/python/os_listdir.htm\n",
    "for folder in os.listdir(path):\n",
    "    combined_path = os.path.join(path, folder, \"*json\")\n",
    "    json_files = glob.glob(combined_path)\n",
    "\n",
    "    for i in range(len(json_files)):\n",
    "        df_temp = extract_data_from_json(json_files[i])\n",
    "        df_list.append(df_temp)\n",
    "        \n",
    "df_cust = pd.concat(df_list)\n",
    "df_cust = drop_unnecessary_columns(df_cust)\n",
    "# https://www.datacamp.com/tutorial/save-as-csv-pandas-dataframe\n",
    "df_cust.to_csv('prices_customers.csv', index = False, encoding='utf-8')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Bereiten Sie die Daten auf die weitere Analyse vor, indem Sie geeignete Datentransformations- und -bereinigungsschritte durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust = pd.read_csv('prices_customers.csv')\n",
    "\n",
    "df_cust['Datum'] = pd.to_datetime(df_cust['Datum'])\n",
    "\n",
    "def combine_price_columns(row):\n",
    "    if pd.isna(row['Preis im 1. Jahr*']):\n",
    "        return row['Preis im 1. Jahr']\n",
    "    return row['Preis im 1. Jahr*']\n",
    "\n",
    "def replace_string_from_row(row, column, string, string_to_replace_with):\n",
    "    if pd.isna(row[column]):\n",
    "        return row[column]\n",
    "    if string in row[column]:\n",
    "        return row[column].replace(string, string_to_replace_with)\n",
    "    return row[column]\n",
    "\n",
    "# Combine the two price columns into one\n",
    "df_cust['Preis'] = df_cust.apply(combine_price_columns, axis = 1)\n",
    "df_cust = df_cust.drop(columns = ['Preis im 1. Jahr*', 'Preis im 1. Jahr'])\n",
    "\n",
    "df_cust['Vertragslaufzeit'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Vertragslaufzeit', \" Monate\", \"\"), axis=1)\n",
    "df_cust['Vertragslaufzeit'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Vertragslaufzeit', \" Monat\", \"\"), axis=1)\n",
    "# Fill NaN values, so that dtype can be converted to int\n",
    "df_cust['Vertragslaufzeit'] = df_cust['Vertragslaufzeit'].fillna(0)\n",
    "df_cust['Vertragslaufzeit'] = df_cust['Vertragslaufzeit'].astype(int)\n",
    "\n",
    "df_cust['Preis'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Preis', \" €/Monat\", \"\"), axis=1)\n",
    "# Change decimal comma, to decimal point for float conversion\n",
    "df_cust['Preis'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Preis', \",\", \".\"), axis=1)\n",
    "df_cust['Preis'] = df_cust['Preis'].astype(float)\n",
    "df_cust = df_cust.rename(columns = {'Preis' : 'Preis im 1. Jahr/ pro Monat in €', 'Vertragslaufzeit' : 'Vertragslaufzeit in Monaten'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Wie viele verschiedene Tarife wurden insgesamt angeboten? Zu wie vielen Tagen sind pro Stadt Daten vorhanden? Wie viele verschiedene Anbieter haben insgesamt Tarife angeboten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tariffe = df_cust['Tarif'].unique()\n",
    "print(\"Anzahl verschiedender Tarife:\" , len(unique_tariffe))\n",
    "\n",
    "# Occuriung Städte in the DataSet\n",
    "number_of_total_cities = len(df_cust['Stadt'].unique())\n",
    "\n",
    "# Group with any aggregation to get all unique Datum/Stadt combination entries\n",
    "grouped_date_city = df_cust.groupby(['Datum', 'Stadt']).agg(count=('Stadt', 'count')).reset_index()\n",
    "# Group and count how many different Stadt rows there are for each given date\n",
    "grouped_date = grouped_date_city.groupby( ['Datum'])['Stadt'].count()\n",
    "# Filter out the dates that don't have an entry for every Stadt of the DataSet\n",
    "filtered_dates = grouped_date[grouped_date == number_of_total_cities]\n",
    "print(\"Daten für alle Städte sind an\", len(filtered_dates), \"Tagen vorhanden\")\n",
    "\n",
    "unique_anbieter = df_cust['Anbieter'].unique()\n",
    "print(\"Anzahl der Anbieter die insgesamt Tarife angeboten haben:\", len(unique_anbieter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Ermitteln Sie, welche unterschiedlichen Tarife in Amberg angeboten wurden und visualisieren Sie exemplarisch für die Stadt Amberg den Füllgrad der Daten. Erstellen Sie dazu eine HeatMap, aus der hervorgeht, an welchen Tagen es zu welchen der ermittelten Tarife Angebotsdaten gab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quellenverzeichnis\n",
    "<a id = \"quellenverzeichnis\"></a>\n",
    "\n",
    "[1] https://www.geeksforgeeks.org/how-to-read-all-csv-files-in-a-folder-in-pandas/\n",
    "\n",
    "[2] https://statistikguru.de/python/python-auflisten-dateien-verzeichnis.html\n",
    "\n",
    "[3] https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
