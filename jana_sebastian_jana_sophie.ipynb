{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektarbeit Data Analytics\n",
    "\n",
    "Sebastian Jana,\n",
    "Sophie Jana\n",
    "\n",
    "## Inhaltsverzeichnis\n",
    "<a id =\"inhaltsverzeichnis\"></a>\n",
    "\n",
    "[1. Aufgabe](#aufgabe1)\n",
    "\n",
    "2. Aufgabe\n",
    "\n",
    "3. Aufgabe\n",
    "\n",
    "4. Aufgabe\n",
    "5. Aufgabe\n",
    "\n",
    "[6. Aufgabe](#aufgabe6)\n",
    "\n",
    "[7. Quellenverzeichnis](#quellenverzeichnis)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1 (Datenvorbereitung)\n",
    "<a id = \"aufgabe1\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a) Einlesen der CSV Dateien, welche die Stromerzeugungsdaten und die Börsenstrompreise enthalten, als Dataframe df_hourly.\n",
    "\n",
    "Nach dem ersten Zusammenführen haben wir festgestellt, dass die Datumsspalte je nach CSV-Datei unterschiedliche Namen für Sommerzeit und Winterzeit hat. Dies führt dazu, dass beim Zusammenführen zwei separate Spalten entstehen. Um dies zu vermeiden, prüfen wir bereits beim Einlesen der Dateien die Spaltennamen und führen sie zu einer einheitlichen Spalte „Datum“ im df_hourly zusammen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources for reading csv files from one folder[1],[2]\n",
    "path = './Daten/Strompreisdaten'\n",
    "# List all files (.csv) in the given path\n",
    "csv_files = glob.glob(os.path.join(path, \"*csv\"))\n",
    "\n",
    "df_list = []\n",
    "for i in range(len(csv_files)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(csv_files[i], sep = \",\")\n",
    "        for column in df_temp.columns:\n",
    "            # Combine the date columns, by getting rid of the naming difference in csv source\n",
    "            if 'Datum (MESZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MESZ)':'DateTime'})\n",
    "            elif 'Datum (MEZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MEZ)':'DateTime'})\n",
    "        df_list.append(df_temp)\n",
    "    except Exception as err: \n",
    "        print(\"Fehler beim Einlesen des Files: \", err)\n",
    "    \n",
    "df_hourly = pd.concat(df_list)\n",
    "df_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Zur besseren anschließenden Analyse überführen wir die Datumsspalte (vorher dytpe object) in ein Date-Time-Format. Überprüfung, ob nach der Konvertierung invalide Datumswerte existieren, was nicht der Fall ist.\n",
    "Alle anderen Spalten haben den dtype float64 und werden so belassen.\n",
    "Entfernung aller Datensätze, die nicht im Betrachtungszeitraum liegen (2020-2024). Durch Filterung über das Jahr werden 48 Einträge entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_hourly.shape)\n",
    "# Converting the column \"DateTime\" from dtype object to DateTime format\n",
    "# Invalid values are converted to NaT (Not a Time)\n",
    "# Source: [3]\n",
    "df_hourly['DateTime'] = pd.to_datetime(df_hourly['DateTime'], errors=\"coerce\")\n",
    "print(df_hourly.dtypes)\n",
    "print(df_hourly['DateTime'].isna().any())\n",
    "\n",
    "\n",
    "\n",
    "# Create column \"Date\" from the Column \"DateTime\" [4]\n",
    "df_hourly = df_hourly[(df_hourly['DateTime'].dt.year >= 2020) & (df_hourly['DateTime'].dt.year <= 2024)]\n",
    "\n",
    "# 48 rows deleted\n",
    "print(df_hourly.shape) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Beurteilung der Datenqualität und notwenige Datenbereinigungsschritte. \n",
    "Qualität der Datumsdaten wurde durch Konvertierung schon überprüft. df_hourly enthält nur Werte für die Jahre 2020-2024. Dataframe enthält keine Null-Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df_hourly.isnull().sum())\n",
    "print(df_hourly.notnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Erzeugung eines Dataframes df_daily, das für jeden Tag die aggregierten Werte der Leistung der erneuerbaren und nicht erneuerbaren Energiequellen, sowie den täglichen Mittelwert des Börsenpreis enthält. Diese Art der Gruppierung ist sinnvoll für die weitere Analyse, um Trends auf Tagesbasis zu analysieren.\n",
    "\n",
    "Zur Gruppierung nach Tagen machen wir aus der DateTime nur noch das Datum, indem wir die Uhrzeit entfernen. Anschließend gruppieren wir die Daten nach Datum, wobei die Leistung nicht erneuerbarer und erneuererbarer Energie jeweils für den Tag aufsummiert wird. Zudem gruppieren wir nochmals nach dem Tag und berechnen für jeden Tag den mittleren Börsenpreis. Abschließend joinen wir zu einem gemeinsamen Dataframe df_daily. Zur klaren Lesbarkeit benennen wir die DateTime Spalte wieder in Datum zurück."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly ['DateTime'] = df_hourly['DateTime'].dt.date\n",
    "\n",
    "df_daily = df_hourly.groupby('DateTime')[[\"Leistung nicht erneuerbar (MW)\", 'Leistung erneuerbar (MW)' ]].sum()\n",
    "\n",
    "df_mean = df_hourly.groupby('DateTime')['Day Ahead Auktion Preis (EUR/MWh)'].mean()\n",
    "\n",
    "df_daily = df_daily.join(df_mean).reset_index()\n",
    "\n",
    "# Rename column DateTime in Date\n",
    "df_daily = df_daily.rename(columns = {\"DateTime\": \"Datum\"})\n",
    "\n",
    "df_daily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 6 (Analyse von Stromtarif-Angeboten für Endkunden)\n",
    "<a id = \"aufgabe6\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a)  Einlesen der JSON-Preisvergleichdaten in einem DataFrame df_cust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Daten/Endkundenpreise/'\n",
    "\n",
    "def extract_date_from_filepath(file):\n",
    "    file = file.replace(path, \"\")\n",
    "    # Concatenate the date out of fixed year 2024 and month/day from folder name\n",
    "    return \"2024-\" + file[0:5]\n",
    "\n",
    "def extract_data_from_json(file):\n",
    "    assert file.endswith(\".json\"), \"Keine json-Datei uebergeben\"\n",
    "    try:\n",
    "        # Read and load the json file\n",
    "        df_temp = pd.read_json(json_files[i])\n",
    "        # Transpose the table: convert the rows to columns\n",
    "        df_temp = df_temp.T\n",
    "        # Index = Number of entry in the json file\n",
    "        df_temp['Angebotsnummer'] = df_temp.index\n",
    "        # Add date from filename as column\n",
    "        df_temp['Datum'] = extract_date_from_filepath(file)\n",
    "        \n",
    "        return df_temp\n",
    "    except:\n",
    "        print(\"Datei konnte nicht gelesen werden.\")\n",
    "\n",
    "\n",
    "path = './Daten/Endkundenpreise/'\n",
    "df_list = []\n",
    "# https://www.tutorialspoint.com/python/os_listdir.htm\n",
    "for folder in os.listdir(path):\n",
    "    combined_path = os.path.join(path, folder, \"*json\")\n",
    "    json_files = glob.glob(combined_path)\n",
    "\n",
    "    for i in range(len(json_files)):\n",
    "        df_temp = extract_data_from_json(json_files[i])\n",
    "        df_list.append(df_temp)\n",
    "        \n",
    "df_cust = pd.concat(df_list)\n",
    "df_cust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quellenverzeichnis\n",
    "<a id = \"quellenverzeichnis\"></a>\n",
    "\n",
    "[1] https://www.geeksforgeeks.org/how-to-read-all-csv-files-in-a-folder-in-pandas/\n",
    "\n",
    "[2] https://statistikguru.de/python/python-auflisten-dateien-verzeichnis.html\n",
    "\n",
    "[3] https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "\n",
    "[4] https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.year.html#pandas.Series.dt.year\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
