{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektarbeit Data Analytics\n",
    "\n",
    "Sebastian Jana,\n",
    "Sophie Jana\n",
    "\n",
    "## Inhaltsverzeichnis\n",
    "<a id =\"inhaltsverzeichnis\"></a>\n",
    "\n",
    "[1. Aufgabe](#aufgabe1)\n",
    "\n",
    "2. Aufgabe\n",
    "\n",
    "3. Aufgabe\n",
    "\n",
    "4. Aufgabe\n",
    "5. Aufgabe\n",
    "\n",
    "[6. Aufgabe](#aufgabe6)\n",
    "\n",
    "[7. Quellenverzeichnis](#quellenverzeichnis)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1 (Datenvorbereitung)\n",
    "<a id = \"aufgabe1\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a) Einlesen der CSV Dateien, welche die Stromerzeugungsdaten und die Börsenstrompreise enthalten, als Dataframe df_hourly.\n",
    "\n",
    "Nach dem ersten Zusammenführen haben wir festgestellt, dass die Datumsspalte je nach CSV-Datei unterschiedliche Namen für Sommerzeit und Winterzeit hat. Dies führt dazu, dass beim Zusammenführen zwei separate Spalten entstehen. Um dies zu vermeiden, prüfen wir bereits beim Einlesen der Dateien die Spaltennamen und führen sie zu einer einheitlichen Spalte „Datum“ im df_hourly zusammen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources for reading csv files from one folder[1],[2]\n",
    "path = './Daten/Strompreisdaten'\n",
    "# List all files (.csv) in the given path\n",
    "csv_files = glob.glob(os.path.join(path, \"*csv\"))\n",
    "\n",
    "df_list = []\n",
    "for i in range(len(csv_files)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(csv_files[i], sep = \",\")\n",
    "        for column in df_temp.columns:\n",
    "            # Combine the date columns, by getting rid of the naming difference in csv source\n",
    "            if 'Datum (MESZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MESZ)':'Datum'})\n",
    "            elif 'Datum (MEZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MEZ)':'Datum'})\n",
    "        df_list.append(df_temp)\n",
    "    except Exception as err: \n",
    "        print(\"Fehler beim Einlesen des Files: \", err)\n",
    "    \n",
    "df_hourly = pd.concat(df_list)\n",
    "df_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Zur besseren anschließenden Analyse überführen wir die Datumsspalte (vorher dytpe object) in ein Date-Time-Format. Überprüfung, ob nach der Konvertierung invalide Datumswerte existieren, was nicht der Fall ist.\n",
    "Alle anderen Spalten haben den dtype float64 und werden so belassen.\n",
    "Entfernung aller Datensätze, die nicht im Betrachtungszeitraum liegen (2020-2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_hourly.shape)\n",
    "# Converting the column \"Datum\" from dtype object to DateTime format\n",
    "# Invalid values are converted to NaT (Not a Time)\n",
    "# Source: [3]\n",
    "df_hourly['Datum'] = pd.to_datetime(df_hourly['Datum'], errors=\"coerce\")\n",
    "print(df_hourly.dtypes)\n",
    "\n",
    "\n",
    "print(df_hourly['Datum'].isna().any())\n",
    "\n",
    "# Erstelle eine Spalte mit dem Jahr aus der Datumsspalte\n",
    "df_hourly['Jahr'] = df_hourly['Datum'].dt.year\n",
    "\n",
    "# Filter: Jahre außerhalb des Bereichs 2020–2024\n",
    "df_false_year = df_hourly[(df_hourly['Jahr'] < 2020) | (df_hourly['Jahr'] > 2024)]\n",
    "\n",
    "print(df_false_year.shape)\n",
    "df_false_year\n",
    "#df_hourly = df_hourly[(df_hourly['Datum'] >= '2020-01-01') & (df_hourly['Datum'] <= '2024-12-31')]\n",
    "#df_hourly.shape\n",
    "#df_hourly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Beurteilung der Datenqualität und notwenige Datenbereinigungsschritte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 6 (Analyse von Stromtarif-Angeboten für Endkunden)\n",
    "<a id = \"aufgabe6\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a) Führen Sie die gegebenen Preisvergleichdaten in einem DataFrame namens df_cust zusammen. Exportieren Sie diesen als CSV-Datei namens prices_customers.csv und laden Sie diese mit Ihrer Abgabe auf Moodle hoch. Verwerfen Sie bitte zur Minimierung der Dateigröße alle Spalten, die im weiteren Verlauf nicht mehr verwendet werden. Kommentieren Sie nun den Code zur Datensatzgenerierung aus und lesen Sie die CSV-Datei in den DataFrame df_cust erneut aus dieser Datei ein.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path = './Daten/Endkundenpreise/'\n",
    "\n",
    "def extract_date_from_filepath(file):\n",
    "    file = file.replace(path, \"\")\n",
    "    # Concatenate the date out of fixed year 2024 and month/day from folder name\n",
    "    return \"2024-\" + file[0:5]\n",
    "\n",
    "def extract_data_from_json(file):\n",
    "    assert file.endswith(\".json\"), \"Keine json-Datei uebergeben\"\n",
    "    try:\n",
    "        # Read and load the json file\n",
    "        df_temp = pd.read_json(json_files[i])\n",
    "        # Transpose the table: convert the rows to columns\n",
    "        df_temp = df_temp.T\n",
    "        # Add date from filename as column\n",
    "        df_temp['Datum'] = extract_date_from_filepath(file)\n",
    "        \n",
    "        return df_temp\n",
    "    except:\n",
    "        print(\"Datei konnte nicht gelesen werden.\")\n",
    "\n",
    "def drop_unnecessary_columns(df):\n",
    "    columns_to_drop = ['Postleitzahl', 'Jahresverbrauch', 'Abschlagszahlung', 'Verlängerung', 'Kündigungsfrist', 'Grundpreis', 'Arbeitspreis', 'Preisgarantie', 'Grundpreisrabatt:', 'Neukundenbonus', 'Sofortbonus', 'Arbeitspreisrabatt', 'Zusätzlicher Aktionsbonus', 'Blitzbonus', 'Abschlagsrabatt', 'Grundpreisrabatt', 'Winterprämie']\n",
    "    return df.drop(columns = columns_to_drop)\n",
    "\n",
    "df_list = []\n",
    "# https://www.tutorialspoint.com/python/os_listdir.htm\n",
    "for folder in os.listdir(path):\n",
    "    combined_path = os.path.join(path, folder, \"*json\")\n",
    "    json_files = glob.glob(combined_path)\n",
    "\n",
    "    for i in range(len(json_files)):\n",
    "        df_temp = extract_data_from_json(json_files[i])\n",
    "        df_list.append(df_temp)\n",
    "        \n",
    "df_cust = pd.concat(df_list)\n",
    "df_cust = drop_unnecessary_columns(df_cust)\n",
    "# https://www.datacamp.com/tutorial/save-as-csv-pandas-dataframe\n",
    "df_cust.to_csv('prices_customers.csv', index = False, encoding='utf-8')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Bereiten Sie die Daten auf die weitere Analyse vor, indem Sie geeignete Datentransformations- und -bereinigungsschritte durchführen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cust = pd.read_csv('prices_customers.csv')\n",
    "print(\"Zeilen vor Bereinigung:\", df_cust.shape[0])\n",
    "\n",
    "df_cust['Datum'] = pd.to_datetime(df_cust['Datum'])\n",
    "\n",
    "def combine_price_columns(row):\n",
    "    if pd.isna(row['Preis im 1. Jahr*']):\n",
    "        return row['Preis im 1. Jahr']\n",
    "    return row['Preis im 1. Jahr*']\n",
    "\n",
    "def replace_string_from_row(row, column, string, string_to_replace_with):\n",
    "    if pd.isna(row[column]):\n",
    "        return row[column]\n",
    "    if string in row[column]:\n",
    "        return row[column].replace(string, string_to_replace_with)\n",
    "    return row[column]\n",
    "\n",
    "# Combine the two price columns into one\n",
    "df_cust['Preis'] = df_cust.apply(combine_price_columns, axis = 1)\n",
    "df_cust = df_cust.drop(columns = ['Preis im 1. Jahr*', 'Preis im 1. Jahr'])\n",
    "# Drop rows with NaN as Preis, because those rows aren't viable for a comparison later on\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "df_cust = df_cust.dropna(subset=['Preis'])\n",
    "\n",
    "df_cust['Vertragslaufzeit'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Vertragslaufzeit', \" Monate\", \"\"), axis=1)\n",
    "df_cust['Vertragslaufzeit'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Vertragslaufzeit', \" Monat\", \"\"), axis=1)\n",
    "# Fill NaN values, so that dtype can be converted to int\n",
    "df_cust['Vertragslaufzeit'] = df_cust['Vertragslaufzeit'].fillna(0)\n",
    "df_cust['Vertragslaufzeit'] = df_cust['Vertragslaufzeit'].astype(int)\n",
    "\n",
    "df_cust['Preis'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Preis', \" €/Monat\", \"\"), axis=1)\n",
    "# Change decimal comma, to decimal point for float conversion\n",
    "df_cust['Preis'] = df_cust.apply(lambda row: replace_string_from_row(row, 'Preis', \",\", \".\"), axis=1)\n",
    "df_cust['Preis'] = df_cust['Preis'].astype(float)\n",
    "df_cust = df_cust.rename(columns = {'Preis' : 'Preis im 1. Jahr/ pro Monat in €', 'Vertragslaufzeit' : 'Vertragslaufzeit in Monaten'})\n",
    "\n",
    "print(\"Zeilen nach Bereinigung:\", df_cust.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Wie viele verschiedene Tarife wurden insgesamt angeboten? Zu wie vielen Tagen sind pro Stadt Daten vorhanden? Wie viele verschiedene Anbieter haben insgesamt Tarife angeboten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tariffe = df_cust['Tarif'].unique()\n",
    "print(\"Anzahl verschiedender Tarife:\" , len(unique_tariffe))\n",
    "\n",
    "# Occuring Städte in the DataSet\n",
    "number_of_total_cities = len(df_cust['Stadt'].unique())\n",
    "\n",
    "# Group with any aggregation to get all unique Datum/Stadt combination entries\n",
    "grouped_date_city = df_cust.groupby(['Datum', 'Stadt']).agg(Count=('Stadt', 'count')).reset_index()\n",
    "# Group and count how many different Stadt rows there are for each given date\n",
    "grouped_date = grouped_date_city.groupby( ['Datum'])['Stadt'].count()\n",
    "# Filter out the dates that don't have an entry for every Stadt of the DataSet\n",
    "filtered_dates = grouped_date[grouped_date == number_of_total_cities]\n",
    "print(\"Daten für alle Städte sind an\", len(filtered_dates), \"Tagen vorhanden\")\n",
    "\n",
    "unique_anbieter = df_cust['Anbieter'].unique()\n",
    "print(\"Anzahl der Anbieter die insgesamt Tarife angeboten haben:\", len(unique_anbieter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Ermitteln Sie, welche unterschiedlichen Tarife in Amberg angeboten wurden und visualisieren Sie exemplarisch für die Stadt Amberg den Füllgrad der Daten. Erstellen Sie dazu eine HeatMap, aus der hervorgeht, an welchen Tagen es zu welchen der ermittelten Tarife Angebotsdaten gab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amberg = df_cust[df_cust['Stadt'] == 'Amberg']\n",
    "\n",
    "unique_tariffe_amberg = df_amberg['Tarif'].unique()\n",
    "print(\"Anzahl verschiedender Tarife:\" , len(unique_tariffe_amberg))\n",
    "\n",
    "plt.figure(figsize=(25, 30))\n",
    "# HeatMap: green = the Tariff is offered for the given day, none/white = no offering \n",
    "plt.scatter(df_amberg['Datum'], df_amberg['Tarif'], color ='green', alpha=0.75)\n",
    "\n",
    "# https://stackoverflow.com/questions/57796673/switching-month-numbers-to-month-names-on-x-axis-of-histogram-matplotlib\n",
    "plt.gca().xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%b'))\n",
    "plt.gca().xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator())\n",
    "\n",
    "plt.xlabel('Datum', fontsize=16) \n",
    "plt.ylabel('Tarif', fontsize=16)\n",
    "plt.title('Verschiedene Tarife für Amberg', fontsize=20)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Visualisieren Sie die durchschnittliche Preisentwicklung im Verlauf des Jahres 2024 über alle Tarife und Orte hinweg. Berücksichtigen Sie dabei nur Tarife, bei denen die Vertragslaufzeit mindestens 12 Monate beträgt. Verwenden Sie dazu den Preis im 1. Jahr, der den monatlichen Preis unter Berücksichtigung des Grundpreises, des Arbeitspreises und von Bonuszahlungen o.ä. enthält. Untersuchen Sie anschließend den Zusammenhang zum Börsenstrompreis, indem Sie geeignete Kenngrößen berechnen und weitere Diagramme erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_12_months = df_cust[df_cust['Vertragslaufzeit in Monaten'] >= 12]\n",
    "df_mean_prices = filtered_12_months.groupby(['Datum']).agg(Mean =('Preis im 1. Jahr/ pro Monat in €', 'mean')).reset_index()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(df_mean_prices['Datum'], df_mean_prices['Mean'], label = 'Line', color = 'red')\n",
    "\n",
    "#https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.ylim.html\n",
    "# Start line plot at 0, to not overdramatize the change in consumer price\n",
    "plt.ylim(bottom = 0, top = 100)\n",
    "\n",
    "plt.xlabel('Datum', fontsize=16) \n",
    "plt.ylabel('Preis pro Monat im 1. Jahr in €', fontsize=16)\n",
    "plt.title('Durchschnittlicher Endkundenpreis', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Im Merkmal Anbieter befinden sich kurze Beschreibungen der Anbieter und der Tarife. Erstellen Sie mit Hilfe des Pakets WordCloud eine Wortwolke für die Anbieter-Beschreibungen und untersuchen Sie, welche Schlagworte besonders häufig auftreten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_buzzwords_from_anbieter(row):\n",
    "    anbieter_words = row['Anbieter'].split() # Isolate each word of Anbieter\n",
    "    words_to_remove = [\n",
    "        'der', 'die', 'das', 'und', 'ein', 'eine', 'mit', 'ist', 'den', 'dem', 'zu', 'von', 'vom', \n",
    "        'auf', 'im', 'an', 'für', 'am', 'als', 'es', 'aber', 'auch', 'aus', 'bei', 'dass', \n",
    "        'du', 'er', 'sie', 'wir', 'ihr', 'ihnen', 'ihm', 'euch', 'mir', 'mich', \n",
    "        'mein', 'meine', 'dein', 'deine', 'sein', 'seine', 'ihr', 'ihre', \n",
    "        'noch', 'schon', 'oder', 'so', 'wie', 'was', 'wer', 'wenn', \n",
    "        'warum', 'weil', 'dann', 'doch', 'nur', 'diese', 'dieser', 'dieses', \n",
    "        'jeder', 'jede', 'jedes', 'keiner', 'keine', 'kein', 'welche', 'welcher', \n",
    "        'man', 'damit', 'immer', 'über', 'unter', 'haben', 'hat', 'sein', 'sind', 'war', 'waren', \n",
    "        'haben', 'habe', 'hatte', 'hätten'\n",
    "    ]\n",
    "\n",
    "    filtered_words = []\n",
    "    \n",
    "    for word in anbieter_words:\n",
    "        if word.lower() not in words_to_remove:\n",
    "            filtered_words.append(word)\n",
    "\n",
    "    # https://www.w3schools.com/python/ref_string_join.asp\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "df_cust['Anbieter'] = df_cust.apply(remove_non_buzzwords_from_anbieter, axis = 1)\n",
    "# Create one big String out of the Anbieter column\n",
    "combined_text = ' '.join(df_cust['Anbieter'])\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=500, background_color='white').generate(combined_text)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')  # No axes for the word cloud\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quellenverzeichnis\n",
    "<a id = \"quellenverzeichnis\"></a>\n",
    "\n",
    "[1] https://www.geeksforgeeks.org/how-to-read-all-csv-files-in-a-folder-in-pandas/\n",
    "\n",
    "[2] https://statistikguru.de/python/python-auflisten-dateien-verzeichnis.html\n",
    "\n",
    "[3] https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
