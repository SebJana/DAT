{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektarbeit Data Analytics\n",
    "\n",
    "Sebastian Jana,\n",
    "Sophie Jana\n",
    "\n",
    "## Inhaltsverzeichnis\n",
    "<a id =\"inhaltsverzeichnis\"></a>\n",
    "\n",
    "[1. Aufgabe](#aufgabe1)\n",
    "\n",
    "2. Aufgabe\n",
    "\n",
    "3. Aufgabe\n",
    "\n",
    "4. Aufgabe\n",
    "5. Aufgabe\n",
    "\n",
    "[6. Aufgabe](#aufgabe6)\n",
    "\n",
    "[7. Quellenverzeichnis](#quellenverzeichnis)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 1 (Datenvorbereitung)\n",
    "<a id = \"aufgabe1\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a) Einlesen der CSV Dateien, welche die Stromerzeugungsdaten und die Börsenstrompreise enthalten, als Dataframe df_hourly.\n",
    "\n",
    "Nach dem ersten Zusammenführen haben wir festgestellt, dass die Datumsspalte je nach CSV-Datei unterschiedliche Namen für Sommerzeit und Winterzeit hat. Dies führt dazu, dass beim Zusammenführen zwei separate Spalten entstehen. Um dies zu vermeiden, prüfen wir bereits beim Einlesen der Dateien die Spaltennamen und führen sie zu einer einheitlichen Spalte „Datum“ im df_hourly zusammen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sources for reading csv files from one folder[1],[2]\n",
    "path = './Daten/Strompreisdaten'\n",
    "# List all files (.csv) in the given path\n",
    "csv_files = glob.glob(os.path.join(path, \"*csv\"))\n",
    "\n",
    "df_list = []\n",
    "for i in range(len(csv_files)):\n",
    "    try:\n",
    "        df_temp = pd.read_csv(csv_files[i], sep = \",\")\n",
    "        for column in df_temp.columns:\n",
    "            # Combine the date columns, by getting rid of the naming difference in csv source\n",
    "            if 'Datum (MESZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MESZ)':'Datum'})\n",
    "            elif 'Datum (MEZ)' in column:\n",
    "                df_temp = df_temp.rename(columns = {'Datum (MEZ)':'Datum'})\n",
    "        df_list.append(df_temp)\n",
    "    except Exception as err: \n",
    "        print(\"Fehler beim Einlesen des Files: \", err)\n",
    "    \n",
    "df_hourly = pd.concat(df_list)\n",
    "df_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Zur besseren anschließenden Analyse überführen wir die Datumsspalte (vorher dytpe object) in ein Date-Time-Format. Überprüfung, ob nach der Konvertierung invalide Datumswerte existieren, was nicht der Fall ist.\n",
    "Alle anderen Spalten haben den dtype float64 und werden so belassen.\n",
    "Entfernung aller Datensätze, die nicht im Betrachtungszeitraum liegen (2020-2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_hourly.shape)\n",
    "# Converting the column \"Datum\" from dtype object to DateTime format\n",
    "# Invalid values are converted to NaT (Not a Time)\n",
    "# Source: [3]\n",
    "df_hourly['Datum'] = pd.to_datetime(df_hourly['Datum'], errors=\"coerce\")\n",
    "print(df_hourly.dtypes)\n",
    "\n",
    "\n",
    "print(df_hourly['Datum'].isna().any())\n",
    "\n",
    "# Erstelle eine Spalte mit dem Jahr aus der Datumsspalte\n",
    "df_hourly['Jahr'] = df_hourly['Datum'].dt.year\n",
    "\n",
    "# Filter: Jahre außerhalb des Bereichs 2020–2024\n",
    "df_false_year = df_hourly[(df_hourly['Jahr'] < 2020) | (df_hourly['Jahr'] > 2024)]\n",
    "\n",
    "print(df_false_year.shape)\n",
    "df_false_year\n",
    "#df_hourly = df_hourly[(df_hourly['Datum'] >= '2020-01-01') & (df_hourly['Datum'] <= '2024-12-31')]\n",
    "#df_hourly.shape\n",
    "#df_hourly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Beurteilung der Datenqualität und notwenige Datenbereinigungsschritte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufgabe 6 (Analyse von Stromtarif-Angeboten für Endkunden)\n",
    "<a id = \"aufgabe6\"></a>\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)\n",
    "\n",
    "a)  Einlesen der JSON-Preisvergleichdaten in einem DataFrame df_cust\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Daten/Endkundenpreise/'\n",
    "\n",
    "def extract_date_from_filepath(file):\n",
    "    file = file.replace(path, \"\")\n",
    "    # Concatenate the date out of fixed year 2024 and month/day from folder name\n",
    "    return \"2024-\" + file[0:5]\n",
    "\n",
    "def extract_data_from_json(file):\n",
    "    assert file.endswith(\".json\"), \"Keine json-Datei uebergeben\"\n",
    "    try:\n",
    "        # Read and load the json file\n",
    "        df_temp = pd.read_json(json_files[i])\n",
    "        # Transpose the table: convert the rows to columns\n",
    "        df_temp = df_temp.T\n",
    "        # Index = Number of entry in the json file\n",
    "        df_temp['Angebotsnummer'] = df_temp.index\n",
    "        # Add date from filename as column\n",
    "        df_temp['Datum'] = extract_date_from_filepath(file)\n",
    "        \n",
    "        return df_temp\n",
    "    except:\n",
    "        print(\"Datei konnte nicht gelesen werden.\")\n",
    "\n",
    "\n",
    "path = './Daten/Endkundenpreise/'\n",
    "df_list = []\n",
    "# https://www.tutorialspoint.com/python/os_listdir.htm\n",
    "for folder in os.listdir(path):\n",
    "    combined_path = os.path.join(path, folder, \"*json\")\n",
    "    json_files = glob.glob(combined_path)\n",
    "\n",
    "    for i in range(len(json_files)):\n",
    "        df_temp = extract_data_from_json(json_files[i])\n",
    "        df_list.append(df_temp)\n",
    "        \n",
    "df_cust = pd.concat(df_list)\n",
    "df_cust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quellenverzeichnis\n",
    "<a id = \"quellenverzeichnis\"></a>\n",
    "\n",
    "[1] https://www.geeksforgeeks.org/how-to-read-all-csv-files-in-a-folder-in-pandas/\n",
    "\n",
    "[2] https://statistikguru.de/python/python-auflisten-dateien-verzeichnis.html\n",
    "\n",
    "[3] https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html\n",
    "\n",
    "[Zurück zum Inhaltsverzeichnis](#inhaltsverzeichnis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
